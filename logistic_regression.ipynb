{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    train_file = 'train.json.zip'\n",
    "    train = pd.read_json(train_file, orient='records', convert_dates=['created'])\n",
    "    train.reset_index(drop=True, inplace=True)\n",
    "    return train\n",
    "\n",
    "def load_test_data():\n",
    "    test_file = 'test.json.zip'\n",
    "    test = pd.read_json(test_file, orient='records', convert_dates=['created'])\n",
    "    test.reset_index(drop=True, inplace=True)\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data\n",
    "train = load_train_data()\n",
    "\n",
    "# remove outliers\n",
    "# latitude\n",
    "lower = np.percentile(train['latitude'].values, 1)\n",
    "upper = np.percentile(train['latitude'].values, 99)\n",
    "train = train[train['latitude'] > lower]\n",
    "train = train[train['latitude'] < upper]\n",
    "# train.latitude.hist()\n",
    "\n",
    "# longitude\n",
    "lower = np.percentile(train['longitude'].values, 1)\n",
    "upper = np.percentile(train['longitude'].values, 99)\n",
    "train = train[train['longitude'] > lower]\n",
    "train = train[train['longitude'] < upper]\n",
    "# train.longitude.hist()\n",
    "\n",
    "# price\n",
    "upper = np.percentile(train['price'].values, 99)\n",
    "train = train[train['price'] < upper]\n",
    "# train.price.hist()\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display all building on NYC map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import descartes\n",
    "# import geopandas as gpd\n",
    "# from shapely.geometry import Point\n",
    "\n",
    "# def get_geometry(data):\n",
    "#     crs = {'init': 'epsg:4326'}\n",
    "#     geometry=[Point(xy)for xy in zip(data['longitude'], data['latitude'])]\n",
    "#     geo_df = gpd.GeoDataFrame(data,\n",
    "#                             crs = crs,\n",
    "#                             geometry = geometry)\n",
    "#     geo_df.reset_index(inplace=True)\n",
    "#     return geo_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load backgroud NYC map data\n",
    "# vmap = gpd.read_file('NYC_street_map.shp')\n",
    "# vmap_geo = vmap.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# #Process the input data\n",
    "# train_geo = get_geometry(train)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize = (15,15))\n",
    "# vmap_geo.plot(ax=ax, alpha=0.4, color=\"grey\", edgecolor = 'k')\n",
    "# train_geo.plot(ax = ax, markersize = 10, color = 'red', marker = 'o', label='Building')\n",
    "# plt.title('Building location distribution')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_boundary = gpd.read_file('NYC_boundary.shp')\n",
    "# map_boundary_geo = map_boundary.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# fig, ax = plt.subplots(figsize = (15,15))\n",
    "# map_boundary_geo.plot(ax=ax, alpha=0.4, color='black', edgecolor='k')\n",
    "# train_geo.plot(ax = ax, markersize = 10, color = 'red', marker = 'o', label='Building')\n",
    "# plt.title('Building location distribution')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding feature manager id\n",
    "manager_id_df = train.groupby(['manager_id']).agg({'building_id': 'count'}).reset_index()\n",
    "manager_number = manager_id_df['building_id'].shape[0]\n",
    "manager_id_df['building_id'] = np.linspace(1, manager_number, num=manager_number, dtype=int)\n",
    "\n",
    "train = train.merge(manager_id_df, how='left', on='manager_id')\n",
    "del train['building_id_x']\n",
    "train = train.rename(columns={'building_id_y': 'manager_number'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # finding all features\n",
    "# features_dict = {}\n",
    "# def get_features(features):\n",
    "#     for f in features:\n",
    "#         f = f.strip('!')\n",
    "#         f = f.strip('*')\n",
    "#         f = f.strip(' ')\n",
    "        \n",
    "#         if f in features_dict.keys():\n",
    "#             features_dict[f] += 1\n",
    "#         else:\n",
    "#             features_dict[f] = 1\n",
    "            \n",
    "# temp = train['features'].apply(get_features)\n",
    "# features_dict.keys()\n",
    "\n",
    "# feature_columns = {}\n",
    "# feature_list = []\n",
    "# for key in features_dict.keys():\n",
    "#     if features_dict[key] >= 20000:\n",
    "#         feature_list.append(key)\n",
    "#         feature_columns[key] = []\n",
    "        \n",
    "# def get_feature_columns(features):\n",
    "#     for key in feature_columns:\n",
    "#         if key in features:\n",
    "#             feature_columns[key].append(True)\n",
    "#         else:\n",
    "#             feature_columns[key].append(False)\n",
    "            \n",
    "# temp = train['features'].apply(get_feature_columns)\n",
    "# train = pd.concat([train, pd.DataFrame.from_dict(feature_columns)], axis=1)\n",
    "\n",
    "\n",
    "# using external dataset\n",
    "subway = pd.read_csv('NYC_Transit_Subway_Entrance_And_Exit_Data.csv')\n",
    "subway = subway[['Station Name', 'Station Latitude', 'Station Longitude']]\n",
    "subway = subway.groupby(['Station Name']).mean().reset_index(drop=True)\n",
    "\n",
    "from math import cos, asin, sqrt\n",
    "# https://stackoverflow.com/questions/27928/calculate-distance-between-two-latitude-longitude-points-haversine-formula/21623206\n",
    "def distance_pair(lat1, lon1, lat2, lon2):\n",
    "    p = 0.017453292519943295     #Pi/180\n",
    "    a = 0.5 - cos((lat2 - lat1) * p)/2 +  cos(lat1 * p) * cos(lat2 * p) * (1 - cos((lon2 - lon1) * p)) / 2\n",
    "    d_2_point = 6371 *2 * asin(sqrt(a)) #2*R*asin...\n",
    "    return d_2_point\n",
    "distance_pairs = np.vectorize(distance_pair)\n",
    "\n",
    "def get_nearby_subway(location):\n",
    "    distances = distance_pairs(location[0], location[1], subway['Station Latitude'], subway['Station Longitude'])    \n",
    "    return distances[distances < 1].shape[0]\n",
    "    \n",
    "def get_subway_distance(location):\n",
    "    distances = distance_pairs(location[0], location[1], subway['Station Latitude'], subway['Station Longitude'])    \n",
    "    return min(distances)\n",
    "\n",
    "train['feature_number'] = train['features'].apply(len)\n",
    "train['room_number'] = train['bedrooms'] + train['bathrooms']\n",
    "train['photo_number'] = train['photos'].apply(len)\n",
    "train['location'] = train[['latitude', 'longitude']].values.tolist()\n",
    "train['nearby_subway'] = train['location'].apply(get_nearby_subway)\n",
    "train['subway_distance'] = train['location'].apply(get_subway_distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Selection Using Embedded Method (LassoCV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/feature-selection-with-pandas-e3690ad8504b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_features = ['feature_number', 'room_number', 'manager_number', 'photo_number', 'nearby_subway', 'subway_distance', 'price']\n",
    "# from sklearn.linear_model import LassoCV\n",
    "# train['target'] = train['interest_level'].apply(lambda x: 0 if x=='low' else 1 if x=='medium' else 2)\n",
    "# target = train['target']\n",
    "# inputs = train[X_features]\n",
    "\n",
    "# best_features = LassoCV().fit(inputs, target)\n",
    "# print(\"Best alpha using built-in LassoCV: %f\" % best_features.alpha_)\n",
    "# print(\"Best score using built-in LassoCV: %f\" %best_features.score(inputs, target))\n",
    "# coef = pd.Series(best_features.coef_, index=inputs.columns)\n",
    "# print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n",
    "# imp_coef = coef.sort_values()\n",
    "# import matplotlib\n",
    "# matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "# imp_coef.plot(kind = \"barh\")\n",
    "# plt.title(\"Feature importance using Lasso Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = ['feature_number', 'room_number', 'photo_number', 'nearby_subway', 'subway_distance', 'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.690504 (+/- 0.006536)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Model 1\n",
    "\n",
    "X = train[X_features]\n",
    "y = train['interest_level']\n",
    "logistic_model = LogisticRegression(multi_class='multinomial', max_iter=800)\n",
    "\n",
    "# scores = cross_val_score(logistic_model, X, y, cv=5)\n",
    "# print(\"Accuracy: %f (+/- %f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# logistic_model.fit(X_train, y_train)\n",
    "# score_train = logistic_model.score(X_train, y_train)\n",
    "# score_test = logistic_model.score(X_test, y_test)\n",
    "# print(\"Accuracy for training data: %f\" % score_train.mean())\n",
    "# print(\"Accuracy for testing data: %f\" % score_test.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for lr_high: 0.927060 (+/- 0.000439)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for lr_medium: 0.764425 (+/- 0.003866)\n",
      "Accuracy for lr_low: 0.704316 (+/- 0.006808)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model 2\n",
    "train['high'] = train['interest_level'].apply(lambda x: True if x=='high' else False)\n",
    "train['medium'] = train['interest_level'].apply(lambda x: True if x=='medium' else False)\n",
    "train['low'] = train['interest_level'].apply(lambda x: True if x=='low' else False)\n",
    "\n",
    "X = train[X_features]\n",
    "y_high = train['high']\n",
    "y_medium = train['medium']\n",
    "y_low = train['low']\n",
    "\n",
    "lr_high = LogisticRegression(multi_class='ovr')\n",
    "lr_medium = LogisticRegression(multi_class='ovr')\n",
    "lr_low = LogisticRegression(multi_class='ovr')\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores_high = cross_val_score(lr_high, X, y_high, cv=5)\n",
    "print(\"Accuracy for lr_high: %f (+/- %f)\" % (scores_high.mean(), scores_high.std() * 2))\n",
    "scores_medium = cross_val_score(lr_medium, X, y_medium, cv=5)\n",
    "print(\"Accuracy for lr_medium: %f (+/- %f)\" % (scores_medium.mean(), scores_medium.std() * 2))\n",
    "scores_low = cross_val_score(lr_low, X, y_low, cv=5)\n",
    "print(\"Accuracy for lr_low: %f (+/- %f)\" % (scores_low.mean(), scores_low.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['feature_number'] = test['features'].apply(len)\n",
    "test['room_number'] = test['bedrooms'] + test['bathrooms']\n",
    "test['photo_number'] = test['photos'].apply(len)\n",
    "test['location'] = test[['latitude', 'longitude']].values.tolist()\n",
    "test['nearby_subway'] = test['location'].apply(get_nearby_subway)\n",
    "test['subway_distance'] = test['location'].apply(get_subway_distance)\n",
    "test = test.merge(manager_id_df, how='left', on='manager_id')\n",
    "del test['building_id_x']\n",
    "test = test.rename(columns={'building_id_y': 'manager_number'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.concat([test, pd.DataFrame.from_dict(feature_columns)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_null = test[test['manager_number'].isnull()]\n",
    "test_null['manager_number'] = np.zeros(test_null.shape[0])\n",
    "test = test.dropna(subset=['manager_number'])\n",
    "test = pd.concat([test, test_null])\n",
    "test = test.astype({'manager_number':'int64'})\n",
    "# test = test.astype({'Dogs Allowed':'bool', 'Hardwood Floors':'bool', 'Cats Allowed':'bool', 'Elevator':'bool'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[X_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model 1\n",
    "# logistic_model.fit(X, y)\n",
    "# y_test = logistic_model.predict_proba(X_test)\n",
    "# test_data = {'listing_id':test['listing_id'], \n",
    "#              'high':y_test[:,0], \n",
    "#             'medium' : y_test[:,2], \n",
    "#             'low' : y_test[:,1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "lr_high.fit(X, y_high)\n",
    "lr_medium.fit(X, y_medium)\n",
    "lr_low.fit(X, y_low)\n",
    "\n",
    "y_test_high = lr_high.predict_proba(X_test)[:,1]\n",
    "y_test_medium = lr_medium.predict_proba(X_test)[:,1]\n",
    "y_test_low = lr_low.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "test_data = {'listing_id' : test['listing_id'], \n",
    "             'high' : y_test_high, \n",
    "             'medium' : y_test_medium, \n",
    "             'low' : y_test_low}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>high</th>\n",
       "      <th>medium</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7142618</td>\n",
       "      <td>0.070164</td>\n",
       "      <td>0.261234</td>\n",
       "      <td>0.687964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7210040</td>\n",
       "      <td>0.145642</td>\n",
       "      <td>0.278017</td>\n",
       "      <td>0.537015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7174566</td>\n",
       "      <td>0.093342</td>\n",
       "      <td>0.200184</td>\n",
       "      <td>0.698756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7191391</td>\n",
       "      <td>0.131381</td>\n",
       "      <td>0.290551</td>\n",
       "      <td>0.573149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7171695</td>\n",
       "      <td>0.084836</td>\n",
       "      <td>0.275697</td>\n",
       "      <td>0.612100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74282</th>\n",
       "      <td>6946524</td>\n",
       "      <td>0.125432</td>\n",
       "      <td>0.284312</td>\n",
       "      <td>0.586533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74312</th>\n",
       "      <td>6859027</td>\n",
       "      <td>0.106815</td>\n",
       "      <td>0.279251</td>\n",
       "      <td>0.594247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74349</th>\n",
       "      <td>6824740</td>\n",
       "      <td>0.120766</td>\n",
       "      <td>0.262940</td>\n",
       "      <td>0.584180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74517</th>\n",
       "      <td>6875490</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.025620</td>\n",
       "      <td>0.990615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74539</th>\n",
       "      <td>6815248</td>\n",
       "      <td>0.037128</td>\n",
       "      <td>0.170842</td>\n",
       "      <td>0.815742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74659 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       listing_id      high    medium       low\n",
       "0         7142618  0.070164  0.261234  0.687964\n",
       "1         7210040  0.145642  0.278017  0.537015\n",
       "2         7174566  0.093342  0.200184  0.698756\n",
       "3         7191391  0.131381  0.290551  0.573149\n",
       "4         7171695  0.084836  0.275697  0.612100\n",
       "...           ...       ...       ...       ...\n",
       "74282     6946524  0.125432  0.284312  0.586533\n",
       "74312     6859027  0.106815  0.279251  0.594247\n",
       "74349     6824740  0.120766  0.262940  0.584180\n",
       "74517     6875490  0.000198  0.025620  0.990615\n",
       "74539     6815248  0.037128  0.170842  0.815742\n",
       "\n",
       "[74659 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data=test_data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_number',\n",
       " 'room_number',\n",
       " 'photo_number',\n",
       " 'nearby_subway',\n",
       " 'subway_distance',\n",
       " 'price']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.501000716056738\n",
      "0.5045420420420421\n",
      "0.5601835486289282\n"
     ]
    }
   ],
   "source": [
    "# model 2\n",
    "# lr_high\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_high)\n",
    "y_score = lr_high.fit(X_train, y_train).predict(X_test)\n",
    "print(roc_auc_score(y_test, y_score))\n",
    "\n",
    "# lr_medium\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_medium)\n",
    "y_score = lr_medium.fit(X_train, y_train).predict(X_test)\n",
    "print(roc_auc_score(y_test, y_score))\n",
    "\n",
    "# lr_low\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_low)\n",
    "y_score = lr_low.fit(X_train, y_train).predict(X_test)\n",
    "print(roc_auc_score(y_test, y_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model 1\n",
    "# from sklearn.metrics import f1_score\n",
    "# y = y.apply(lambda x: 0 if x=='low' else 1 if x=='medium' else 2)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# y_score = logistic_model.fit(X_train, y_train).predict(X_test)\n",
    "# f1_score(y_test, y_score, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.686503538238554"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
